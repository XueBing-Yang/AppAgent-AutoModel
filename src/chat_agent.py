"""
Chat agent with tool calling and optional vision support.
"""
from __future__ import annotations

import base64
import os
import json
import re
from typing import Any, Dict, List, Optional
from pathlib import Path

import openai
import yaml
from dotenv import load_dotenv

from src.skills import SkillContext, get_skill_specs, execute_skill
from src.workflows.xhs_publish import (
    create_plan as create_xhs_plan,
    detect_xhs_publish_intent,
    extract_phone,
    summarize_progress as summarize_workflow_progress,
    update_step as update_workflow_step,
)

load_dotenv()


_VISION_MODEL_KEYWORDS = ("qwen-vl", "qwen2.5-vl", "qwen3.5-plus", "gpt-4o", "gpt-4-vision", "gemini")


class ChatAgent:
    def __init__(self, config_path: str = "config/settings.yaml"):
        self.config_path = config_path
        self.config = self._load_config(config_path)
        self.client = self._init_client()
        self.model = self.config.get("llm", {}).get("model", "qwen3.5-plus")
        self.enable_thinking = "deepseek" in self.model.lower()
        self.is_vision = any(kw in self.model.lower() for kw in _VISION_MODEL_KEYWORDS)
        self.tools = get_skill_specs()
        self.skill_ctx = SkillContext(config_path=config_path)

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        config_file = Path(config_path)
        if not config_file.exists():
            return {}
        with open(config_file, "r", encoding="utf-8") as f:
            return yaml.safe_load(f) or {}

    def _init_client(self) -> openai.OpenAI:
        llm = self.config.get("llm", {})
        model = llm.get("model", "qwen3.5-plus")
        provider = (llm.get("provider") or "").lower()
        base_url = llm.get("base_url")
        # é˜¿é‡Œäº‘ç™¾ç‚¼ï¼šqwenã€qwen3.5-plus ç­‰å‡ç”¨ DashScope åŒä¸€ endpoint + DASHSCOPE_API_KEY
        if provider == "dashscope":
            api_key = os.getenv("DASHSCOPE_API_KEY")
            if not api_key:
                raise ValueError("ä½¿ç”¨ç™¾ç‚¼/ DashScope æ—¶è¯·åœ¨ .env ä¸­é…ç½® DASHSCOPE_API_KEYï¼ˆé˜¿é‡Œäº‘ç™¾ç‚¼ API Keyï¼‰")
            base_url = base_url or "https://dashscope.aliyuncs.com/compatible-mode/v1"
            return openai.OpenAI(api_key=api_key, base_url=base_url, timeout=120.0)
        # DeepSeek å®˜æ–¹ APIï¼ˆä»…å½“ provider é dashscope ä¸”æ¨¡å‹åä¸º deepseek æ—¶ï¼‰
        if "deepseek" in model.lower():
            api_key = os.getenv("DEEPSEEK_API_KEY") or os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("DEEPSEEK_API_KEY æˆ– OPENAI_API_KEY ç¯å¢ƒå˜é‡å¿…å¡«ï¼ˆDeepSeek å®˜æ–¹ï¼‰")
            base_url = base_url or "https://api.deepseek.com"
            return openai.OpenAI(api_key=api_key, base_url=base_url, timeout=120.0)
        if "qwen" in model.lower():
            api_key = os.getenv("DASHSCOPE_API_KEY")
            if not api_key:
                raise ValueError("DASHSCOPE_API_KEY required for qwen model")
            base_url = base_url or "https://dashscope.aliyuncs.com/compatible-mode/v1"
            return openai.OpenAI(api_key=api_key, base_url=base_url)
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY required")
        return openai.OpenAI(api_key=api_key, base_url=base_url)

    def _system_prompt(self) -> str:
        base = (
            "ä½ æ˜¯ä¸€ä¸ªä¼šå…ˆè§„åˆ’å†æ‰§è¡Œçš„æ™ºèƒ½ä»£ç†ã€‚\n\n"
            "è§„åˆ™ï¼š\n"
            "1) å…ˆç»™å‡ºå¯æ‰§è¡Œè®¡åˆ’ï¼ˆä¸è¶…è¿‡6æ­¥ï¼‰ï¼Œå†è°ƒç”¨å·¥å…·æ‰§è¡Œï¼›\n"
            "2) éå¿…è¦ä¸è¦æé—®ï¼Œåªæœ‰åœ¨ç¼ºå…³é”®è¾“å…¥æ—¶æ‰é—®ï¼ˆä¾‹å¦‚éªŒè¯ç ï¼‰ï¼›\n"
            "3) ä¼˜å…ˆæ‰§è¡Œï¼Œä¸è¦æŠŠå†…éƒ¨è®¡åˆ’é•¿ç¯‡å›å¤ç»™ç”¨æˆ·ï¼›\n"
            "4) å·¥å…·å¤±è´¥æ—¶è¦è°ƒæ•´ç­–ç•¥å¹¶ç»§ç»­ï¼Œä¸è¦é‡å¤ä»é›¶å¼€å§‹ï¼›\n"
            "5) æ”¯æŒç½‘é¡µè‡ªåŠ¨åŒ–å’ŒAndroidè‡ªåŠ¨åŒ–ï¼ˆADB + uiautomator2ï¼‰ä¸¤ç§è·¯å¾„ï¼›\n"
            "6) è°ƒç”¨ android_tap_coordinates æ—¶ï¼Œx å’Œ y å¿…é¡»æ˜¯æ•´æ•°(å¦‚ x=540, y=960)ï¼Œç»ä¸èƒ½ä¼ åˆ—è¡¨æˆ–å­—ç¬¦ä¸²ã€‚\n\n"
            "å°çº¢ä¹¦ç™»å½•å…³é”®é¡ºåºï¼šå¡«æ‰‹æœºå· -> å‹¾é€‰åŒæ„ -> ç‚¹å‡»è·å–éªŒè¯ç  -> å†è¯¢é—®éªŒè¯ç ã€‚\n"
            "å½“ä»»åŠ¡æ˜¯â€œå°çº¢ä¹¦å‘å¸ƒâ€æ—¶ï¼Œé»˜è®¤ä½¿ç”¨Androidæ‰‹æœºç«¯æµç¨‹ï¼Œä¸ä½¿ç”¨PCæµè§ˆå™¨æµç¨‹ã€‚\n"
            "å¯¹äºå°çº¢ä¹¦å‘å¸ƒç±»ä»»åŠ¡ï¼šå…ˆç”¨ web_search æœç´¢ç´ æï¼Œç„¶ååœ¨APPé‡Œç›´æ¥ç‚¹å‡»å‘å¸ƒæŒ‰é’®ï¼Œä¸è¦åœ¨APPå†…æœç´¢ã€‚\n"
        )
        if self.is_vision:
            base += (
                "\nã€è§†è§‰èƒ½åŠ›å·²å¯ç”¨ã€‘\n"
                "ä½ å¯ä»¥çœ‹åˆ°æ‰‹æœºæˆªå›¾ã€‚\n\n"
                "ã€æ™®é€šAPPæ“ä½œç­–ç•¥ã€‘ï¼ˆæˆªå›¾çœ‹çŠ¶æ€ + find_elements å®šä½åæ ‡ï¼‰ï¼š\n"
                "1) ç”¨ android_screenshot æˆªå›¾æ¥ç†è§£å½“å‰ç•Œé¢æ˜¯ä»€ä¹ˆé¡µé¢ã€æœ‰å“ªäº›å…ƒç´ ï¼›\n"
                "2) ç¡®å®šè¦ç‚¹å‡»çš„ç›®æ ‡åï¼Œå…ˆè°ƒç”¨ android_find_elements è·å–è¯¥å…ƒç´ çš„ boundsï¼Œ\n"
                "   ç„¶åè®¡ç®—ä¸­å¿ƒåæ ‡ x=(left+right)/2, y=(top+bottom)/2ï¼Œå†ç”¨ android_tap_coordinates ç‚¹å‡»ï¼›\n"
                "3) å¦‚æœ find_elements æ‰¾ä¸åˆ°ç›®æ ‡ï¼Œå¯å°è¯• android_tap_text/android_tap_resource_id/android_tap_content_descï¼›\n"
                "4) æ¯æ¬¡æ“ä½œåæˆªå›¾ç¡®è®¤ç»“æœï¼Œç¡®ä¿æ“ä½œç”Ÿæ•ˆåå†è¿›è¡Œä¸‹ä¸€æ­¥ã€‚\n\n"
                "ã€æ¸¸æˆå¼•æ“ç•Œé¢ç­–ç•¥ã€‘ï¼ˆå½“ç³»ç»Ÿæç¤º'æ¸¸æˆæ¨¡å¼'æ—¶ä½¿ç”¨æ­¤ç­–ç•¥ï¼‰ï¼š\n"
                "æ¸¸æˆä½¿ç”¨ Unity/Cocos ç­‰å¼•æ“æ¸²æŸ“ï¼Œdump_ui å’Œ find_elements æ— æ³•è¯†åˆ«ä»»ä½•æ¸¸æˆå†…å…ƒç´ ã€‚\n"
                "1) æˆªå›¾ä¸Šä¼šå åŠ çº¢è‰²åæ ‡ç½‘æ ¼çº¿ï¼Œæ¯æ¡çº¿æ—æ ‡æ³¨äº†çœŸå®åƒç´ åæ ‡å€¼ï¼›\n"
                "2) æ ¹æ®ç½‘æ ¼å‚ç…§çº¿åˆ¤æ–­ç›®æ ‡å…ƒç´ çš„ä½ç½®ï¼Œç›´æ¥ç”¨ android_tap_coordinates ç‚¹å‡»ï¼›\n"
                "3) ä¸è¦è°ƒç”¨ android_find_elements / android_dump_ui / android_tap_textï¼ˆä¸€å®šè¿”å›ç©ºï¼‰ï¼›\n"
                "4) ç‚¹å‡»åç«‹åˆ»æˆªå›¾ç¡®è®¤æ˜¯å¦ç”Ÿæ•ˆï¼Œå¦‚æœç•Œé¢æ²¡å˜åŒ–ï¼Œåœ¨ç›®æ ‡é™„è¿‘åç§» Â±30~50px é‡è¯•ï¼›\n"
                "5) ç”¨ç™¾åˆ†æ¯”æ€è€ƒä½ç½®ï¼šä¾‹å¦‚'æŒ‰é’®åœ¨å±å¹•å·¦ä¾§çº¦5%ã€å‚ç›´çº¦80%å¤„' -> x=screen_w*0.05, y=screen_h*0.80ã€‚\n"
            )
        return base

    def _llm_extra_kwargs(self) -> dict:
        """Extra kwargs for chat completions (e.g. enable_thinking for DeepSeek)."""
        if self.enable_thinking:
            return {"extra_body": {"enable_thinking": True}}
        return {}

    @staticmethod
    def _extract_reasoning(msg) -> str:
        """Extract reasoning_content from a DeepSeek thinking-enabled response."""
        rc = getattr(msg, "reasoning_content", None)
        if rc:
            return str(rc).strip()
        extra = getattr(msg, "model_extra", None) or {}
        rc2 = extra.get("reasoning_content")
        if rc2:
            return str(rc2).strip()
        return ""

    @staticmethod
    def _draw_grid_overlay(image_path: str, screen_w: int, screen_h: int) -> Optional[str]:
        """Draw coordinate grid on screenshot to help vision model estimate positions.
        Returns path to the annotated image, or None on failure."""
        try:
            from PIL import Image, ImageDraw, ImageFont
        except ImportError:
            return None
        p = Path(image_path)
        if not p.exists():
            return None
        img = Image.open(p).convert("RGBA")
        overlay = Image.new("RGBA", img.size, (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        img_w, img_h = img.size
        try:
            font = ImageFont.truetype("arial.ttf", max(12, img_h // 60))
        except Exception:
            font = ImageFont.load_default()
        for pct in range(10, 100, 10):
            x = int(img_w * pct / 100)
            real_x = int(screen_w * pct / 100)
            draw.line([(x, 0), (x, img_h)], fill=(255, 50, 50, 90), width=1)
            draw.text((x + 3, 3), str(real_x), fill=(255, 50, 50, 220), font=font)
            y = int(img_h * pct / 100)
            real_y = int(screen_h * pct / 100)
            draw.line([(0, y), (img_w, y)], fill=(255, 50, 50, 90), width=1)
            draw.text((3, y + 3), str(real_y), fill=(255, 50, 50, 220), font=font)
        result = Image.alpha_composite(img, overlay).convert("RGB")
        out_path = str(p.parent / f"{p.stem}_grid{p.suffix}")
        result.save(out_path)
        return out_path

    @staticmethod
    def _encode_image(image_path: str, max_size: int = 1024) -> Optional[str]:
        """Read an image file and return base64-encoded data URI. Resize if Pillow is available."""
        p = Path(image_path)
        if not p.exists() or p.stat().st_size == 0:
            return None
        try:
            from PIL import Image
            import io
            img = Image.open(p)
            w, h = img.size
            if max(w, h) > max_size:
                ratio = max_size / max(w, h)
                img = img.resize((int(w * ratio), int(h * ratio)), Image.LANCZOS)
            buf = io.BytesIO()
            img.save(buf, format="PNG", optimize=True)
            b64 = base64.b64encode(buf.getvalue()).decode()
        except ImportError:
            b64 = base64.b64encode(p.read_bytes()).decode()
        return f"data:image/png;base64,{b64}"

    def _inject_screenshot(
        self,
        messages: List[Dict],
        image_path: str,
        context_text: str = "",
        game_mode: bool = False,
        screen_w: int = 0,
        screen_h: int = 0,
    ) -> bool:
        """Encode screenshot and append as a vision user message. Returns True if injected.
        In game_mode, draws a coordinate grid overlay and uses higher resolution."""
        if not self.is_vision:
            return False
        encode_path = image_path
        res = 1024
        if game_mode and screen_w > 0 and screen_h > 0:
            grid_path = self._draw_grid_overlay(image_path, screen_w, screen_h)
            if grid_path:
                encode_path = grid_path
            res = 1600
        data_uri = self._encode_image(encode_path, max_size=res)
        if not data_uri:
            return False
        content: List[Dict[str, Any]] = []
        if not context_text:
            if game_mode and screen_w > 0:
                orientation = "æ¨ªå±" if screen_w > screen_h else "ç«–å±"
                context_text = (
                    f"å½“å‰æ‰‹æœºå±å¹•æˆªå›¾ï¼ˆ{orientation}ï¼Œå®é™…åˆ†è¾¨ç‡ {screen_w}Ã—{screen_h}ï¼‰ã€‚"
                    f"å›¾ç‰‡ä¸Šå åŠ äº†çº¢è‰²åæ ‡ç½‘æ ¼çº¿ï¼ˆæ¯æ¡çº¿æ—æ ‡æ³¨äº†çœŸå®åƒç´ åæ ‡ï¼‰ã€‚"
                    f"è¯·æ ¹æ®ç½‘æ ¼å‚è€ƒçº¿ç²¾ç¡®å®šä½ç›®æ ‡å…ƒç´ çš„åæ ‡ï¼Œç„¶åç›´æ¥ç”¨ android_tap_coordinates ç‚¹å‡»ã€‚"
                    f"ä¸è¦è°ƒç”¨ android_find_elementsï¼ˆæ¸¸æˆå¼•æ“ç•Œé¢æ— æ³•è¯†åˆ« UI å…ƒç´ ï¼‰ã€‚"
                )
            else:
                context_text = (
                    "å½“å‰æ‰‹æœºå±å¹•æˆªå›¾ï¼Œè¯·æ ¹æ®ç”»é¢åˆ¤æ–­ç•Œé¢çŠ¶æ€ã€‚"
                    "è¦ç‚¹å‡»æŸä¸ªå…ƒç´ æ—¶ï¼Œå…ˆç”¨ android_find_elements è·å–ç²¾ç¡® boundsï¼Œè®¡ç®—ä¸­å¿ƒåæ ‡åå† tapï¼Œä¸è¦ä»æˆªå›¾ä¼°ç®—åæ ‡ã€‚"
                )
        if screen_w > 0 and screen_h > 0 and "åˆ†è¾¨ç‡" not in context_text:
            context_text += f"ï¼ˆå±å¹•åˆ†è¾¨ç‡: {screen_w}Ã—{screen_h}ï¼‰"
        content.append({"type": "text", "text": context_text})
        content.append({"type": "image_url", "image_url": {"url": data_uri}})
        messages.append({"role": "user", "content": content})
        return True

    @staticmethod
    def _emit_tool_insight(emit, name: str, args: dict, result: dict):
        """Emit a short human-readable insight after a successful tool call."""
        if name == "web_search":
            titles = []
            for r in (result.get("results") or [])[:3]:
                t = (r.get("title") or r.get("name") or "")[:40]
                if t:
                    titles.append(t)
            if titles:
                emit("tool_insight", {"tool": name, "text": f"æœç´¢åˆ°: {'; '.join(titles)}"})
        elif name == "browser_start":
            sid = str(result.get("session_id", ""))[:8]
            emit("tool_insight", {"tool": name, "text": f"æµè§ˆå™¨ä¼šè¯å·²åˆ›å»º (id: {sid}...)"})
        elif name == "browser_open":
            url = args.get("url", "")
            emit("tool_insight", {"tool": name, "text": f"å·²æ‰“å¼€é¡µé¢: {url[:60]}"})
        elif name == "browser_get_visible_inputs":
            inputs = result.get("inputs") or []
            btns = result.get("buttons") or []
            emit("tool_insight", {"tool": name, "text": f"å‘ç° {len(inputs)} ä¸ªè¾“å…¥æ¡†, {len(btns)} ä¸ªæŒ‰é’®"})
        elif name == "browser_get_page_source":
            length = len(result.get("html") or result.get("source") or "")
            emit("tool_insight", {"tool": name, "text": f"è·å–åˆ°é¡µé¢æºç  ({length} å­—ç¬¦)"})
        elif name == "browser_fill_by_placeholder":
            emit("tool_insight", {"tool": name, "text": f"å·²å¡«å†™: {args.get('placeholder_substring', '')}"})
        elif name == "browser_click_by_text":
            emit("tool_insight", {"tool": name, "text": f"å·²ç‚¹å‡»: {args.get('text_substring', '')}"})
        elif name == "android_list_devices":
            devs = result.get("devices") or []
            emit("tool_insight", {"tool": name, "text": f"æ£€æµ‹åˆ° {len(devs)} å°è®¾å¤‡: {', '.join(devs[:3])}"})
        elif name == "android_start":
            did = result.get("device_id", "")
            drv = result.get("driver", "adb")
            emit("tool_insight", {"tool": name, "text": f"å·²è¿æ¥è®¾å¤‡ {did} (é©±åŠ¨: {drv})"})
        elif name == "android_open_app":
            pkg = args.get("package", "")
            emit("tool_insight", {"tool": name, "text": f"å·²å¯åŠ¨åº”ç”¨: {pkg}"})
        elif name == "android_tap_text":
            txt = args.get("text", "")
            emit("tool_insight", {"tool": name, "text": f"å·²ç‚¹å‡»æ–‡æœ¬: '{txt}'"})
        elif name == "android_tap_coordinates":
            x, y = args.get("x", "?"), args.get("y", "?")
            emit("tool_insight", {"tool": name, "text": f"å·²ç‚¹å‡»åæ ‡ ({x}, {y})"})
        elif name == "android_tap_resource_id":
            rid = args.get("resource_id", "")
            emit("tool_insight", {"tool": name, "text": f"å·²ç‚¹å‡»èµ„æºID: {rid}"})
        elif name == "android_tap_content_desc":
            desc = args.get("desc", "")
            emit("tool_insight", {"tool": name, "text": f"å·²ç‚¹å‡»æè¿°: '{desc}'"})
        elif name == "android_swipe":
            direction = args.get("direction", "")
            emit("tool_insight", {"tool": name, "text": f"å·²æ»‘åŠ¨: {direction}"})
        elif name == "android_find_elements":
            count = result.get("count", 0)
            emit("tool_insight", {"tool": name, "text": f"æ‰¾åˆ° {count} ä¸ªåŒ¹é…å…ƒç´ "})
        elif name == "android_input_text":
            emit("tool_insight", {"tool": name, "text": "å·²è¾“å…¥æ–‡æœ¬å†…å®¹"})
        elif name == "android_dump_ui":
            xml_len = len(result.get("xml") or "")
            emit("tool_insight", {"tool": name, "text": f"è¯»å–ç•Œé¢æ ‘ ({xml_len} å­—ç¬¦)"})
        elif name == "android_screenshot":
            path = result.get("screenshot", "")
            emit("tool_insight", {"tool": name, "text": f"æˆªå›¾å·²ä¿å­˜: {path}"})
        elif name == "android_get_screen_size":
            w = result.get("width", "?")
            h = result.get("height", "?")
            o = result.get("orientation", "")
            emit("tool_insight", {"tool": name, "text": f"å±å¹•å°ºå¯¸: {w}Ã—{h} ({o})"})

    def chat(
        self,
        user_message: str,
        history: Optional[List[Dict[str, str]]] = None,
        on_step_start: Optional[Any] = None,
        on_step_end: Optional[Any] = None,
        on_event: Optional[Any] = None,
    ) -> Dict[str, Any]:
        """Run one user turn with explicit plan -> execute state transitions."""
        messages = [{"role": "system", "content": self._system_prompt()}]
        if history:
            messages.extend(history)
        messages.append({"role": "user", "content": user_message})

        def emit(event: str, payload: Dict[str, Any]) -> None:
            if on_event:
                try:
                    on_event(event, payload)
                except Exception:
                    pass

        def needs_user_input(reply: str) -> bool:
            if not reply:
                return False
            if "ï¼Ÿ" in reply or "?" in reply:
                return True
            keys = ["è¯·æä¾›", "è¯·è¾“å…¥", "éªŒè¯ç ", "å¯†ç ", "çŸ­ä¿¡ç ", "æˆæƒç "]
            return any(k in reply for k in keys)

        state = "planning"
        emit("state_change", {"state": state})

        workflow_plan: Dict[str, Any] = {}
        mobile_only = False
        if detect_xhs_publish_intent(user_message):
            workflow_plan = create_xhs_plan(user_message)
            mobile_only = True
            emit("plan_created", {"plan": workflow_plan})
            messages.append(
                {
                    "role": "system",
                    "content": (
                        "ä»»åŠ¡è®¡åˆ’å·²å»ºç«‹ï¼Œè¯·æŒ‰è®¡åˆ’æ‰§è¡Œå¹¶æŒç»­æ¨è¿›ï¼š"
                        f"{json.dumps(workflow_plan, ensure_ascii=False)}"
                    ),
                }
            )
            messages.append(
                {
                    "role": "system",
                    "content": (
                        "æœ¬ä»»åŠ¡å¼ºåˆ¶ä½¿ç”¨ Android ç«¯è‡ªåŠ¨åŒ–å‘å¸ƒï¼Œä¸è¦è°ƒç”¨ browser_* å·¥å…·ã€‚\n"
                        "é‡è¦æ‰§è¡Œç­–ç•¥ï¼š\n"
                        "1) å…ˆç”¨ web_search æœç´¢ä¸»é¢˜ç´ æï¼Œä¸è¦åœ¨å°çº¢ä¹¦APPå†…æœç´¢ï¼ˆæµªè´¹æ“ä½œæ­¥éª¤ï¼‰ï¼›\n"
                        "2) æ ¹æ®æœç´¢ç»“æœç›´æ¥ç”Ÿæˆå¸–å­æ ‡é¢˜å’Œæ­£æ–‡ï¼›\n"
                        "3) ç‚¹å‡»ä»»ä½•æŒ‰é’®å‰ï¼Œå…ˆç”¨ android_find_elements æŸ¥æ‰¾ç›®æ ‡å…ƒç´ è·å–ç²¾ç¡® boundsï¼Œ\n"
                        "   è®¡ç®—ä¸­å¿ƒåæ ‡åå†ç”¨ android_tap_coordinates ç‚¹å‡»â€”â€”ä¸è¦ä»æˆªå›¾çŒœåæ ‡ï¼›\n"
                        "4) æ¯æ¬¡æ“ä½œåç”¨ android_screenshot æˆªå›¾ç¡®è®¤æ“ä½œç»“æœï¼›\n"
                        "5) android_tap_coordinates çš„ x å’Œ y å¿…é¡»æ˜¯æ•´æ•°ï¼Œä¸è¦ä¼ å…¥åˆ—è¡¨ã€‚"
                    ),
                }
            )
        else:
            emit("plan_created", {"plan": {"goal": "general_task", "steps": ["analyze", "execute", "respond"]}})

        state = "executing"
        emit("state_change", {"state": state})

        max_rounds = 40
        trace: List[Dict[str, Any]] = []
        step_index = [0]
        active_browser_session_id: Optional[str] = None
        active_android_session_id: Optional[str] = None
        auto_filled_phone = False
        auto_checked_agreement = False
        auto_clicked_code_btn = False
        is_game_ui = False
        screen_w = 0
        screen_h = 0
        find_empty_streak = 0
        last_screenshot_path: Optional[str] = None

        def _run_orchestrated_tool(name: str, args: Dict[str, Any]) -> Dict[str, Any]:
            if on_step_start:
                try:
                    on_step_start(step_index[0], name, args)
                except Exception:
                    pass
            result = execute_skill(self.skill_ctx, name, args)
            if on_step_end:
                try:
                    on_step_end(step_index[0], name, result)
                except Exception:
                    pass
            step_index[0] += 1
            trace.append({"type": "tool_call", "name": name, "arguments": args})
            trace.append({"type": "tool_result", "name": name, "result": result})
            emit(
                "step",
                {
                    "index": step_index[0],
                    "name": name,
                    "args": args,
                    "success": not (isinstance(result, dict) and result.get("success") is False),
                },
            )
            return result

        def _mobile_bootstrap() -> Optional[Dict[str, Any]]:
            """Initialize Android session and open XHS app for mobile-only flow."""
            nonlocal active_android_session_id, screen_w, screen_h
            listed = _run_orchestrated_tool("android_list_devices", {})
            if not isinstance(listed, dict) or not listed.get("success"):
                state_msg = "æœªæ£€æµ‹åˆ°å¯ç”¨ Android è®¾å¤‡ï¼ˆADBï¼‰ã€‚è¯·è¿æ¥æ‰‹æœºå¹¶å¼€å¯ USB è°ƒè¯•åé‡è¯•ã€‚"
                return {
                    "reply": state_msg,
                    "messages": messages,
                    "trace": trace,
                    "state": "waiting_user",
                    "plan": workflow_plan,
                    "requires_user_input": True,
                }
            started = _run_orchestrated_tool("android_start", {})
            if not isinstance(started, dict) or not started.get("success"):
                return {
                    "reply": "Android ä¼šè¯å¯åŠ¨å¤±è´¥ï¼Œè¯·ç¡®è®¤ adb devices å¯è§ä¸”è®¾å¤‡å·²æˆæƒã€‚",
                    "messages": messages,
                    "trace": trace,
                    "state": "waiting_user",
                    "plan": workflow_plan,
                    "requires_user_input": True,
                }
            active_android_session_id = str(started.get("session_id"))
            if screen_w == 0:
                from src.android_tool import get_screen_size
                sz = get_screen_size(active_android_session_id)
                if isinstance(sz, dict) and sz.get("success"):
                    screen_w = sz["width"]
                    screen_h = sz["height"]
            _run_orchestrated_tool(
                "android_open_app",
                {"session_id": active_android_session_id, "package": "com.xingin.xhs"},
            )
            _run_orchestrated_tool("android_wait", {"session_id": active_android_session_id, "wait_ms": 3000})
            if workflow_plan:
                update_workflow_step(workflow_plan, "open_xhs", "completed", "å·²æ‰“å¼€æ‰‹æœºç«¯å°çº¢ä¹¦")
            if self.is_vision:
                shot = _run_orchestrated_tool(
                    "android_screenshot",
                    {"session_id": active_android_session_id, "output_path": "tmp/xhs_boot.png"},
                )
                img_path = (shot.get("screenshot") or "") if isinstance(shot, dict) else ""
                messages.append({
                    "role": "system",
                    "content": (
                        f"Android ä¼šè¯å·²å°±ç»ªï¼Œsession_id={active_android_session_id}ã€‚"
                        "åç»­è°ƒç”¨ android_* å·¥å…·æ—¶æ— éœ€æ‰‹åŠ¨ä¼ å…¥ session_idï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ³¨å…¥ã€‚\n"
                        "å½“å‰å·²æ‰“å¼€å°çº¢ä¹¦ï¼Œä¸‹æ–¹é™„æœ‰å¯åŠ¨åçš„æ‰‹æœºæˆªå›¾ï¼Œè¯·ç›´æ¥æ ¹æ®ç”»é¢åˆ¤æ–­ç•Œé¢çŠ¶æ€ã€‚"
                    ),
                })
                if img_path:
                    ctx = (
                        "å°çº¢ä¹¦å¯åŠ¨åçš„ç•Œé¢æˆªå›¾ï¼Œè¯·åˆ¤æ–­å½“å‰çŠ¶æ€ï¼ˆé¦–é¡µ/ç™»å½•/å…¶ä»–ï¼‰ã€‚"
                        "æ³¨æ„ï¼šæˆªå›¾ä»…ç”¨äºç†è§£ç•Œé¢ï¼Œç‚¹å‡»æ—¶å¿…é¡»å…ˆç”¨ android_find_elements è·å–ç›®æ ‡å…ƒç´ çš„ç²¾ç¡® bounds å†è®¡ç®—ä¸­å¿ƒåæ ‡ç‚¹å‡»ï¼Œä¸è¦ä»æˆªå›¾çŒœåæ ‡ã€‚"
                    )
                    if screen_w:
                        ctx += f"ï¼ˆå±å¹•åˆ†è¾¨ç‡: {screen_w}Ã—{screen_h}ï¼‰"
                    self._inject_screenshot(messages, img_path, context_text=ctx,
                                            screen_w=screen_w, screen_h=screen_h)
                    emit("decision_summary", {"text": "ğŸ“· å¯åŠ¨æˆªå›¾å·²å‘é€ç»™è§†è§‰æ¨¡å‹"})
            else:
                dumped = _run_orchestrated_tool("android_dump_ui", {"session_id": active_android_session_id, "max_chars": 20000})
                messages.append({
                    "role": "system",
                    "content": (
                        f"Android ä¼šè¯å·²å°±ç»ªï¼Œsession_id={active_android_session_id}ã€‚"
                        "åç»­è°ƒç”¨ android_* å·¥å…·æ—¶æ— éœ€æ‰‹åŠ¨ä¼ å…¥ session_idï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ³¨å…¥ã€‚\n"
                        "å½“å‰å·²æ‰“å¼€å°çº¢ä¹¦ï¼ŒUI æ ‘æ‘˜è¦å¦‚ä¸‹ï¼ˆç”¨äºåç»­å®šä½ï¼‰ï¼š\n"
                        f"{json.dumps(dumped, ensure_ascii=False)[:4000]}"
                    ),
                })
            emit("decision_summary", {"text": "å·²åˆ‡æ¢æ‰‹æœºç«¯å‘å¸ƒæµç¨‹å¹¶å®Œæˆå°çº¢ä¹¦å¯åŠ¨"})
            return None

        def _run_mobile_login_autopilot() -> None:
            nonlocal auto_filled_phone, auto_checked_agreement, auto_clicked_code_btn
            if not active_android_session_id:
                return
            all_text = "\n".join([str(m.get("content", "")) for m in messages if isinstance(m, dict)])
            phone = extract_phone(all_text)
            if phone and not auto_filled_phone:
                for token in ("è¾“å…¥æ‰‹æœºå·", "æ‰‹æœºå·", "æ‰‹æœºå·ç "):
                    t = _run_orchestrated_tool(
                        "android_tap_text",
                        {"session_id": active_android_session_id, "text": token},
                    )
                    if isinstance(t, dict) and t.get("success"):
                        break
                ir = _run_orchestrated_tool(
                    "android_input_text",
                    {"session_id": active_android_session_id, "text": phone, "clear": True},
                )
                auto_filled_phone = bool(isinstance(ir, dict) and ir.get("success"))
                if workflow_plan and auto_filled_phone:
                    update_workflow_step(workflow_plan, "prepare_login", "in_progress", "å·²åœ¨æ‰‹æœºç«¯å¡«å†™æ‰‹æœºå·")
            if auto_filled_phone and not auto_checked_agreement:
                for token in ("æˆ‘å·²é˜…è¯»å¹¶åŒæ„", "åŒæ„", "ç”¨æˆ·åè®®"):
                    ar = _run_orchestrated_tool(
                        "android_tap_text",
                        {"session_id": active_android_session_id, "text": token},
                    )
                    if isinstance(ar, dict) and ar.get("success"):
                        auto_checked_agreement = True
                        break
            if auto_filled_phone and not auto_clicked_code_btn:
                for token in ("è·å–éªŒè¯ç ", "å‘é€éªŒè¯ç ", "è·å–"):
                    cr = _run_orchestrated_tool(
                        "android_tap_text",
                        {"session_id": active_android_session_id, "text": token},
                    )
                    if isinstance(cr, dict) and cr.get("success"):
                        auto_clicked_code_btn = True
                        if workflow_plan:
                            update_workflow_step(workflow_plan, "prepare_login", "completed", "å·²è§¦å‘æ‰‹æœºç«¯éªŒè¯ç å‘é€")
                        break

        if mobile_only:
            boot_result = _mobile_bootstrap()
            if boot_result is not None:
                emit("state_change", {"state": "waiting_user"})
                return boot_result

        for _ in range(max_rounds):
            emit("decision_summary", {"text": "æ­£åœ¨åˆ†æä»»åŠ¡ï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨..."})
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=self.tools,
                tool_choice="auto",
                **self._llm_extra_kwargs(),
            )
            msg = response.choices[0].message

            reasoning = self._extract_reasoning(msg)
            if reasoning:
                emit("thinking", {"text": reasoning})

            tool_calls = getattr(msg, "tool_calls", None)
            if not tool_calls:
                reply = (msg.content or "").strip()
                if workflow_plan:
                    emit("decision_summary", {"text": summarize_workflow_progress(workflow_plan)})
                if needs_user_input(reply):
                    state = "waiting_user"
                    emit("state_change", {"state": state})
                    return {
                        "reply": reply,
                        "messages": messages,
                        "trace": trace,
                        "state": state,
                        "plan": workflow_plan,
                        "requires_user_input": True,
                    }
                if not reply and workflow_plan:
                    pending = [s for s in workflow_plan.get("steps", []) if s.get("status") not in ("completed",)]
                    if pending:
                        next_title = pending[0].get("title", "ä¸‹ä¸€æ­¥")
                        emit("decision_summary", {"text": f"å›å¤ä¸ºç©ºï¼Œä»»åŠ¡æœªå®Œæˆï¼Œç»§ç»­æ‰§è¡Œ: {next_title}"})
                        messages.append({
                            "role": "system",
                            "content": (
                                "ä½ çš„å›å¤ä¸ºç©ºä¸”æœªè°ƒç”¨ä»»ä½•å·¥å…·ï¼Œä½†ä»»åŠ¡å°šæœªå®Œæˆã€‚"
                                f"å¾…å®Œæˆæ­¥éª¤: {', '.join(s.get('title','') for s in pending)}ã€‚"
                                "è¯·ç«‹å³è°ƒç”¨å·¥å…·ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥ï¼Œä¸è¦è¿”å›ç©ºå›å¤ã€‚"
                                "ç³»ç»Ÿä¼šè‡ªåŠ¨æ³¨å…¥ session_idï¼Œä½ æ— éœ€æ‰‹åŠ¨ä¼ å…¥ã€‚"
                            ),
                        })
                        continue
                state = "completed"
                emit("state_change", {"state": state})
                return {"reply": reply, "messages": messages, "trace": trace, "state": state, "plan": workflow_plan}

            content_text = (msg.content or "").strip()
            if content_text and not reasoning:
                emit("thinking", {"text": content_text})

            tool_names = [c.function.name for c in tool_calls]
            emit("decision_summary", {"text": f"å†³å®šè°ƒç”¨: {', '.join(tool_names)}"})

            messages.append({"role": "assistant", "tool_calls": tool_calls, "content": msg.content or ""})
            for call in tool_calls:
                name = call.function.name
                args_raw = call.function.arguments or "{}"
                try:
                    args = json.loads(args_raw)
                except json.JSONDecodeError:
                    args = {}
                if (
                    isinstance(args, dict)
                    and name.startswith("browser_")
                    and name not in {"browser_start", "browser_close"}
                    and "session_id" not in args
                    and active_browser_session_id
                ):
                    args["session_id"] = active_browser_session_id
                if (
                    isinstance(args, dict)
                    and name.startswith("android_")
                    and name not in {"android_start", "android_list_devices", "android_stop"}
                    and "session_id" not in args
                    and active_android_session_id
                ):
                    args["session_id"] = active_android_session_id
                trace.append({"type": "tool_call", "name": name, "arguments": args})
                if on_step_start:
                    try:
                        on_step_start(step_index[0], name, args)
                    except Exception:
                        pass
                if mobile_only and name.startswith("browser_"):
                    result = {
                        "success": False,
                        "error": "pc_browser_disabled",
                        "message": "This Xiaohongshu task must run on Android tools.",
                    }
                elif name == "browser_start" and active_browser_session_id:
                    result = {"session_id": active_browser_session_id, "reused_by_orchestrator": True}
                elif name == "android_start" and active_android_session_id:
                    result = {"success": True, "session_id": active_android_session_id, "reused_by_orchestrator": True}
                else:
                    result = execute_skill(self.skill_ctx, name, args)
                if on_step_end:
                    try:
                        on_step_end(step_index[0], name, result)
                    except Exception:
                        pass
                step_index[0] += 1
                trace.append({"type": "tool_result", "name": name, "result": result})
                if isinstance(result, dict) and result.get("session_id"):
                    if name.startswith("browser_"):
                        active_browser_session_id = str(result.get("session_id"))
                    if name.startswith("android_"):
                        active_android_session_id = str(result.get("session_id"))
                messages.append(
                    {
                        "role": "tool",
                        "tool_call_id": call.id,
                        "name": name,
                        "content": json.dumps(result, ensure_ascii=False),
                    }
                )
                if isinstance(result, dict) and result.get("success") is False:
                    err = result.get("error") or result.get("message") or "unknown_error"
                    emit("decision_summary", {"text": f"{name} å¤±è´¥: {err}ï¼Œè‡ªåŠ¨è°ƒæ•´ç­–ç•¥"})
                    messages.append(
                        {
                            "role": "system",
                            "content": (
                                f"å·¥å…· {name} æ‰§è¡Œå¤±è´¥ï¼Œé”™è¯¯={err}ã€‚"
                                "ä½ å¿…é¡»æ‰¿è®¤å¤±è´¥å¹¶è°ƒæ•´ç­–ç•¥ï¼šä¸è¦é‡å¤ä»å¤´å¯åŠ¨ä¼šè¯ï¼›"
                                "ä¼˜å…ˆå¤ç”¨å½“å‰ sessionï¼Œé‡æ–°è¯»å–é¡µé¢å…ƒç´ åå†é‡è¯•ã€‚"
                            ),
                        }
                    )
                elif isinstance(result, dict) and result.get("success") is not False:
                    ChatAgent._emit_tool_insight(emit, name, args, result)
                # --- Game mode detection ---
                if name == "android_dump_ui" and isinstance(result, dict) and result.get("success"):
                    xml_text = result.get("xml") or ""
                    node_count = xml_text.count("<node") + xml_text.count("<android.")
                    if not is_game_ui and (len(xml_text) < 3000 or node_count < 5):
                        is_game_ui = True
                        emit("decision_summary", {"text": "ğŸ® æ£€æµ‹åˆ°æ¸¸æˆå¼•æ“ç•Œé¢ï¼Œå·²åˆ‡æ¢ä¸ºæ¸¸æˆæ“ä½œæ¨¡å¼"})
                        if active_android_session_id and screen_w == 0:
                            from src.android_tool import get_screen_size
                            sz = get_screen_size(active_android_session_id)
                            if isinstance(sz, dict) and sz.get("success"):
                                screen_w = sz["width"]
                                screen_h = sz["height"]
                        messages.append({
                            "role": "system",
                            "content": (
                                "âš ï¸ æ¸¸æˆæ¨¡å¼å·²æ¿€æ´»ï¼šå½“å‰ä¸ºæ¸¸æˆå¼•æ“æ¸²æŸ“ç•Œé¢ï¼Œdump_ui/find_elements æ— æ³•è¯†åˆ«ä»»ä½•æ¸¸æˆå†…å…ƒç´ ã€‚\n"
                                "è¯·åˆ‡æ¢ä¸ºã€æ¸¸æˆå¼•æ“ç•Œé¢ç­–ç•¥ã€‘ï¼š\n"
                                "- ä¸è¦å†è°ƒç”¨ android_find_elements / android_dump_ui / android_tap_text\n"
                                "- æˆªå›¾ä¸Šæœ‰çº¢è‰²åæ ‡ç½‘æ ¼å‚è€ƒçº¿ï¼Œæ ¹æ®ç½‘æ ¼è¯»å–ç›®æ ‡çš„åƒç´ åæ ‡\n"
                                "- ç›´æ¥ç”¨ android_tap_coordinates ç‚¹å‡»ï¼Œç‚¹å‡»åæˆªå›¾ç¡®è®¤\n"
                                "- å¦‚æœç‚¹å‡»æ— æ•ˆï¼Œåœ¨é™„è¿‘ Â±30~50px åç§»é‡è¯•\n"
                                + (f"- å±å¹•åˆ†è¾¨ç‡: {screen_w}Ã—{screen_h}\n" if screen_w else "")
                            ),
                        })
                if name == "android_find_elements" and isinstance(result, dict):
                    found = result.get("count", 0) or len(result.get("elements") or [])
                    if found == 0:
                        find_empty_streak += 1
                    else:
                        find_empty_streak = 0
                    if not is_game_ui and find_empty_streak >= 2:
                        is_game_ui = True
                        emit("decision_summary", {"text": "ğŸ® è¿ç»­å¤šæ¬¡ find_elements è¿”å›ç©ºï¼Œåˆ‡æ¢ä¸ºæ¸¸æˆæ“ä½œæ¨¡å¼"})
                        if active_android_session_id and screen_w == 0:
                            from src.android_tool import get_screen_size
                            sz = get_screen_size(active_android_session_id)
                            if isinstance(sz, dict) and sz.get("success"):
                                screen_w = sz["width"]
                                screen_h = sz["height"]
                        messages.append({
                            "role": "system",
                            "content": (
                                "âš ï¸ æ¸¸æˆæ¨¡å¼å·²æ¿€æ´»ï¼šfind_elements è¿ç»­è¿”å›ç©ºï¼Œå½“å‰ç•Œé¢å¯èƒ½æ˜¯æ¸¸æˆå¼•æ“æ¸²æŸ“ã€‚\n"
                                "è¯·åœæ­¢è°ƒç”¨ android_find_elements / android_dump_ui / android_tap_textã€‚\n"
                                "æ”¹ä¸ºæˆªå›¾åæ ¹æ®åæ ‡ç½‘æ ¼ç›´æ¥ android_tap_coordinates ç‚¹å‡»ã€‚\n"
                                + (f"å±å¹•åˆ†è¾¨ç‡: {screen_w}Ã—{screen_h}\n" if screen_w else "")
                            ),
                        })
                # --- Fetch screen size on session start ---
                if name == "android_start" and isinstance(result, dict) and result.get("success") and screen_w == 0:
                    sid = result.get("session_id") or active_android_session_id
                    if sid:
                        from src.android_tool import get_screen_size
                        sz = get_screen_size(sid)
                        if isinstance(sz, dict) and sz.get("success"):
                            screen_w = sz["width"]
                            screen_h = sz["height"]
                # --- Screenshot injection with game mode awareness ---
                if name in ("android_screenshot", "browser_screenshot") and isinstance(result, dict) and result.get("success"):
                    img_path = result.get("screenshot") or result.get("path") or ""
                    if img_path:
                        last_screenshot_path = img_path
                    if img_path and self.is_vision:
                        injected = self._inject_screenshot(
                            messages, img_path,
                            game_mode=is_game_ui,
                            screen_w=screen_w, screen_h=screen_h,
                        )
                        if injected:
                            mode_tag = "ğŸ®" if is_game_ui else "ğŸ“·"
                            emit("decision_summary", {"text": f"{mode_tag} æˆªå›¾å·²å‘é€ç»™è§†è§‰æ¨¡å‹åˆ†æ"})
                if mobile_only and name == "android_dump_ui" and isinstance(result, dict) and result.get("success"):
                    _run_mobile_login_autopilot()
                # Deterministic login assist for Xiaohongshu:
                # after inputs are detected, auto-fill phone and click code button.
                if (not mobile_only) and name == "browser_get_visible_inputs" and isinstance(result, dict) and result.get("success"):
                    inputs = result.get("inputs", []) or []
                    all_text = "\n".join(
                        [str(m.get("content", "")) for m in messages if isinstance(m, dict)]
                    )
                    phone = extract_phone(all_text)
                    has_phone_input = any("æ‰‹æœºå·" in str(x.get("placeholder", "")) for x in inputs if isinstance(x, dict))
                    if active_browser_session_id and phone and has_phone_input and not auto_filled_phone:
                        fill_result = _run_orchestrated_tool(
                            "browser_fill_by_placeholder",
                            {
                                "session_id": active_browser_session_id,
                                "placeholder_substring": "è¾“å…¥æ‰‹æœºå·",
                                "text": phone,
                            },
                        )
                        auto_filled_phone = bool(isinstance(fill_result, dict) and fill_result.get("success"))
                        if workflow_plan:
                            update_workflow_step(workflow_plan, "prepare_login", "in_progress", "å·²å¡«å†™æ‰‹æœºå·")
                        messages.append(
                            {
                                "role": "system",
                                "content": f"ç³»ç»Ÿè‡ªåŠ¨æ‰§è¡Œï¼šå·²å°è¯•å¡«å†™æ‰‹æœºå·ã€‚ç»“æœ={json.dumps(fill_result, ensure_ascii=False)}",
                            }
                        )
                    if active_browser_session_id and auto_filled_phone and not auto_checked_agreement:
                        agree_result = _run_orchestrated_tool(
                            "browser_check_agreement",
                            {
                                "session_id": active_browser_session_id,
                            },
                        )
                        auto_checked_agreement = bool(isinstance(agree_result, dict) and agree_result.get("success"))
                        messages.append(
                            {
                                "role": "system",
                                "content": f"ç³»ç»Ÿè‡ªåŠ¨æ‰§è¡Œï¼šå·²å°è¯•å‹¾é€‰åŒæ„é€‰é¡¹ã€‚ç»“æœ={json.dumps(agree_result, ensure_ascii=False)}",
                            }
                        )
                    if active_browser_session_id and auto_filled_phone and not auto_clicked_code_btn:
                        click_result: Dict[str, Any] = {"success": False, "error": "not_run"}
                        for token in ("è·å–éªŒè¯ç ", "è·å–", "å‘é€éªŒè¯ç "):
                            click_result = _run_orchestrated_tool(
                                "browser_click_by_text",
                                {
                                    "session_id": active_browser_session_id,
                                    "text_substring": token,
                                },
                            )
                            if isinstance(click_result, dict) and click_result.get("success"):
                                break
                        auto_clicked_code_btn = bool(isinstance(click_result, dict) and click_result.get("success"))
                        if auto_clicked_code_btn and workflow_plan:
                            update_workflow_step(workflow_plan, "prepare_login", "completed", "å·²è§¦å‘éªŒè¯ç å‘é€")
                        messages.append(
                            {
                                "role": "system",
                                "content": f"ç³»ç»Ÿè‡ªåŠ¨æ‰§è¡Œï¼šå·²å°è¯•ç‚¹å‡»éªŒè¯ç æŒ‰é’®ã€‚ç»“æœ={json.dumps(click_result, ensure_ascii=False)}",
                            }
                        )

        state = "review"
        emit("state_change", {"state": state})
        try:
            final_resp = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                **self._llm_extra_kwargs(),
            )
            final_msg_obj = final_resp.choices[0].message
            final_reasoning = self._extract_reasoning(final_msg_obj)
            if final_reasoning:
                emit("thinking", {"text": final_reasoning})
            final_msg = (final_msg_obj.content or "").strip()
            if final_msg:
                state = "completed"
                emit("state_change", {"state": state})
                return {"reply": final_msg, "messages": messages, "trace": trace, "state": state, "plan": workflow_plan}
        except Exception:
            pass

        state = "failed"
        emit("state_change", {"state": state})
        return {
            "reply": "æ‰§è¡Œå·²ç»“æŸï¼Œä½†æœªèƒ½ç”Ÿæˆç¨³å®šæœ€ç»ˆå›å¤ã€‚",
            "messages": messages,
            "trace": trace,
            "state": state,
            "plan": workflow_plan,
        }
