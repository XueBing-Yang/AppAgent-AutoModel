"""
å°è¯´å¤„ç†æ¨¡å—ï¼šå°†è¾“å…¥çš„å°è¯´åˆ‡åˆ†ä¸ºå¤§é‡ç‰‡æ®µ
"""
import re
from typing import List, Dict, Union
from pathlib import Path


class NovelProcessor:
    """å°è¯´å¤„ç†å™¨ï¼šè´Ÿè´£åˆ‡åˆ†å°è¯´ä¸ºç‰‡æ®µ"""
    
    def __init__(self, min_length: int = 50, max_length: int = 500):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            min_length: ç‰‡æ®µæœ€å°é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
            max_length: ç‰‡æ®µæœ€å¤§é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
        """
        self.min_length = min_length
        self.max_length = max_length
    
    def load_novel(self, file_path: str) -> str:
        """
        åŠ è½½å°è¯´æ–‡ä»¶
        
        Args:
            file_path: å°è¯´æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ.txt, .mdç­‰ï¼‰
        
        Returns:
            å°è¯´æ–‡æœ¬å†…å®¹
        """
        path = Path(file_path)
        if not path.exists():
            raise FileNotFoundError(f"å°è¯´æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # å°è¯•ä¸åŒçš„ç¼–ç 
        encodings = ['utf-8', 'gbk', 'gb2312', 'utf-8-sig']
        for encoding in encodings:
            try:
                with open(path, 'r', encoding=encoding) as f:
                    content = f.read()
                print(f"âœ… æˆåŠŸåŠ è½½å°è¯´æ–‡ä»¶: {file_path} (ç¼–ç : {encoding})")
                return content
            except UnicodeDecodeError:
                continue
        
        raise ValueError(f"æ— æ³•è¯»å–æ–‡ä»¶ï¼Œå°è¯•äº†ç¼–ç : {encodings}")
    
    def clean_text(self, text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬ï¼šç§»é™¤å¤šä½™ç©ºç™½ã€ç»Ÿä¸€æ¢è¡Œç¬¦ç­‰
        
        Args:
            text: åŸå§‹æ–‡æœ¬
        
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        # ç»Ÿä¸€æ¢è¡Œç¬¦
        text = text.replace('\r\n', '\n').replace('\r', '\n')
        
        # ç§»é™¤å¤šä¸ªè¿ç»­çš„ç©ºè¡Œ
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # ç§»é™¤è¡Œé¦–è¡Œå°¾ç©ºç™½
        lines = [line.strip() for line in text.split('\n')]
        text = '\n'.join(lines)
        
        return text.strip()

    def split_by_sentences(self, text: str) -> List[Dict[str, any]]:
        """
        æŒ‰å¥å­åˆ‡åˆ†æ–‡æœ¬ï¼Œä¿ç•™æ ‡ç‚¹ç¬¦å·ï¼Œå¤„ç†å¼•å·å†…çš„å¯¹è¯ï¼Œè€ƒè™‘æ®µè½ç»“æ„

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            å¥å­åˆ—è¡¨ï¼Œæ¯ä¸ªå¥å­åŒ…å«æ–‡æœ¬ã€æ˜¯å¦æ®µè½æœ«å°¾ç­‰ä¿¡æ¯
        """
        # é¦–å…ˆæŒ‰æ®µè½åˆ†å‰²ï¼ˆä¿ç•™æ®µè½ç»“æ„ï¼‰
        # æ®µè½åˆ†éš”ç¬¦ï¼šä¸¤ä¸ªæˆ–æ›´å¤šæ¢è¡Œç¬¦ï¼Œæˆ–è€…å•ä¸ªæ¢è¡Œç¬¦ï¼ˆå¦‚æœå‰åéƒ½æ˜¯éç©ºè¡Œï¼‰
        paragraphs = self._split_paragraphs(text)
        
        sentences = []
        for para_idx, paragraph in enumerate(paragraphs):
            # æŒ‰å¥å­åˆ†å‰²ï¼ˆè€ƒè™‘å¼•å·ï¼‰
            para_sentences = self._split_sentences_in_paragraph(paragraph)
            
            for sent_idx, sentence in enumerate(para_sentences):
                is_para_end = (sent_idx == len(para_sentences) - 1)
                sentences.append({
                    'text': sentence,
                    'paragraph_index': para_idx,
                    'is_paragraph_end': is_para_end
                })
        
        return sentences
    
    def _split_paragraphs(self, text: str) -> List[str]:
        """
        æŒ‰æ®µè½åˆ†å‰²æ–‡æœ¬ï¼ˆä¿ç•™æ®µè½ç»“æ„ï¼‰
        
        Args:
            text: æ–‡æœ¬å†…å®¹
        
        Returns:
            æ®µè½åˆ—è¡¨
        """
        # æŒ‰ä¸¤ä¸ªæˆ–æ›´å¤šæ¢è¡Œç¬¦åˆ†å‰²æ®µè½
        # ä½¿ç”¨éè´ªå©ªåŒ¹é…ï¼Œé¿å…åŒ¹é…è¿‡å¤šçš„æ¢è¡Œç¬¦
        paragraphs = re.split(r'\n{2,}', text)
        paragraphs = [p.strip() for p in paragraphs if p.strip()]
        return paragraphs
    
    def _split_sentences_in_paragraph(self, paragraph: str) -> List[str]:
        """
        åœ¨æ®µè½å†…æŒ‰å¥å­åˆ†å‰²ï¼Œä¿ç•™æ ‡ç‚¹ç¬¦å·ï¼Œå¤„ç†å¼•å·å†…çš„å¯¹è¯
        
        Args:
            paragraph: æ®µè½æ–‡æœ¬
        
        Returns:
            å¥å­åˆ—è¡¨ï¼ˆåŒ…å«æ ‡ç‚¹ç¬¦å·ï¼‰
        """
        sentences = []
        
        # ä½¿ç”¨çŠ¶æ€æœºæ–¹æ³•å¤„ç†å¼•å·
        # é¿å…åœ¨å¼•å·å†…åˆ‡åˆ†å¥å­
        current_sentence = ""
        in_quotes = False
        quote_char = None  # æ”¯æŒä¸åŒçš„å¼•å·ï¼š"" "" '' ã€ã€ ã€Œã€ç­‰
        
        i = 0
        while i < len(paragraph):
            char = paragraph[i]
            
            # æ£€æµ‹å¼•å·å¼€å§‹/ç»“æŸ
            # æ”¯æŒå¤šç§å¼•å·ç±»å‹ï¼šè‹±æ–‡å¼•å·ã€ä¸­æ–‡å¼•å·ã€ä¹¦åå·ç­‰
            # ä½¿ç”¨Unicodeå­—ç¬¦ç é¿å…å­—ç¬¦ä¸²è§£æé—®é¢˜
            quote_chars = [
                '"', '"', '"', '"',  # è‹±æ–‡åŒå¼•å·ï¼ˆå·¦ã€å³ã€ç›´å¼•å·ï¼‰
                "'", "'", "'", "'",  # è‹±æ–‡å•å¼•å·ï¼ˆå·¦ã€å³ã€ç›´å¼•å·ï¼‰
                'ã€', 'ã€', 'ã€Œ', 'ã€'  # ä¸­æ–‡å¼•å·ï¼ˆä¹¦åå·ã€å¼•å·ï¼‰
            ]
            if char in quote_chars:
                if not in_quotes:
                    in_quotes = True
                    quote_char = char
                else:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯é…å¯¹çš„å¼•å·
                    is_pair = (char == quote_char) or \
                             (char in ['"', '"'] and quote_char in ['"', '"']) or \
                             (char in ["'", "'"] and quote_char in ["'", "'"]) or \
                             (char == 'ã€' and quote_char == 'ã€') or \
                             (char == 'ã€' and quote_char == 'ã€Œ')
                    if is_pair:
                        in_quotes = False
                        quote_char = None
            
            current_sentence += char
            
            # å¦‚æœä¸åœ¨å¼•å·å†…ï¼Œæ£€æŸ¥å¥å­ç»“æŸæ ‡å¿—
            if not in_quotes and char in ['ã€‚', 'ï¼', 'ï¼Ÿ']:
                # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸæ­£çš„å¥å­ç»“å°¾ï¼ˆä¸æ˜¯çœç•¥å·çš„ä¸€éƒ¨åˆ†ï¼‰
                # ç®€å•å¤„ç†ï¼šå¦‚æœæ˜¯è¿ç»­çš„å¥å·ï¼Œå¯èƒ½æ˜¯çœç•¥å·
                if char == 'ã€‚' and i + 1 < len(paragraph) and paragraph[i + 1] == 'ã€‚':
                    # å¯èƒ½æ˜¯çœç•¥å·ï¼Œç»§ç»­
                    i += 1
                    continue
                
                sentences.append(current_sentence.strip())
                current_sentence = ""
            
            i += 1
        
        # å¤„ç†æœ€åä¸€ä¸ªå¥å­ï¼ˆå¯èƒ½æ²¡æœ‰ç»“å°¾æ ‡ç‚¹ï¼‰
        if current_sentence.strip():
            sentences.append(current_sentence.strip())
        
        # è¿‡æ»¤ç©ºå¥å­
        sentences = [s for s in sentences if s]
        return sentences
    
    def create_fragments(self, sentences: List[Dict[str, any]]) -> List[Dict[str, any]]:
        """
        å°†å¥å­ç»„åˆæˆç‰‡æ®µï¼Œä¼˜å…ˆåœ¨æ®µè½è¾¹ç•Œåˆ‡åˆ†
        
        Args:
            sentences: å¥å­åˆ—è¡¨ï¼ˆå­—å…¸æ ¼å¼ï¼ŒåŒ…å«textã€is_paragraph_endç­‰ä¿¡æ¯ï¼‰
        
        Returns:
            ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªç‰‡æ®µåŒ…å«æ–‡æœ¬å’Œå…ƒæ•°æ®
        """
        fragments = []
        current_fragment = []
        current_length = 0
        
        for i, sent_dict in enumerate(sentences):
            sentence = sent_dict['text']
            is_para_end = sent_dict.get('is_paragraph_end', False)
            sentence_length = len(sentence)
            
            # å¦‚æœå•ä¸ªå¥å­å°±è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œéœ€è¦å•ç‹¬å¤„ç†
            if sentence_length > self.max_length:
                # å…ˆä¿å­˜å½“å‰ç‰‡æ®µ
                if current_fragment:
                    fragment_text = ''.join([s['text'] for s in current_fragment])
                    if len(fragment_text) >= self.min_length:
                        fragments.append({
                            'text': fragment_text,
                            'index': len(fragments),
                            'length': len(fragment_text),
                            'sentence_count': len(current_fragment),
                            'paragraph_count': len(set(s.get('paragraph_index', 0) for s in current_fragment))
                        })
                    current_fragment = []
                    current_length = 0
                
                # å°†è¶…é•¿å¥å­æŒ‰é€—å·åˆ‡åˆ†ï¼ˆä½œä¸ºæœ€åæ‰‹æ®µï¼‰
                parts = re.split(r'([ï¼Œã€])', sentence)
                temp_frag = []
                temp_len = 0
                for j in range(0, len(parts), 2):
                    part = parts[j] if j < len(parts) else ''
                    punct = parts[j + 1] if j + 1 < len(parts) else ''
                    full_part = part + punct
                    
                    if temp_len + len(full_part) > self.max_length and temp_frag:
                        fragment_text = ''.join(temp_frag)
                        if len(fragment_text) >= self.min_length:
                            fragments.append({
                                'text': fragment_text,
                                'index': len(fragments),
                                'length': len(fragment_text),
                                'sentence_count': 1,
                                'paragraph_count': 1
                            })
                        temp_frag = []
                        temp_len = 0
                    
                    temp_frag.append(full_part)
                    temp_len += len(full_part)
                
                if temp_frag:
                    fragment_text = ''.join(temp_frag)
                    if len(fragment_text) >= self.min_length:
                        fragments.append({
                            'text': fragment_text,
                            'index': len(fragments),
                            'length': len(fragment_text),
                            'sentence_count': 1,
                            'paragraph_count': 1
                        })
                continue
            
            # å…ˆæ·»åŠ åˆ°å½“å‰ç‰‡æ®µï¼ˆä¸´æ—¶ï¼‰
            current_fragment.append(sent_dict)
            current_length += sentence_length
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»“æŸå½“å‰ç‰‡æ®µï¼ˆåŒ…å«å½“å‰å¥å­ï¼‰
            should_end = False
            
            # æƒ…å†µ1ï¼šè¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œå¿…é¡»ç»“æŸ
            if current_length > self.max_length:
                should_end = True
            
            # æƒ…å†µ2ï¼šè¾¾åˆ°æœ€å°é•¿åº¦ï¼Œä¸”åœ¨æ®µè½æœ«å°¾ï¼Œä¼˜å…ˆç»“æŸ
            elif current_length >= self.min_length and is_para_end:
                should_end = True
            
            # æƒ…å†µ3ï¼šè¾¾åˆ°æœ€å°é•¿åº¦ï¼Œä¸”ä¸‹ä¸€ä¸ªå¥å­æ˜¯æ®µè½å¼€å§‹ï¼Œåœ¨æ®µè½è¾¹ç•Œç»“æŸ
            elif current_length >= self.min_length and i + 1 < len(sentences):
                next_sent = sentences[i + 1]
                # å¦‚æœä¸‹ä¸€å¥æ˜¯æ®µè½å¼€å§‹ï¼Œå½“å‰å¥æ˜¯æ®µè½ç»“æŸï¼Œåˆ™åœ¨æ­¤å¤„ç»“æŸ
                if is_para_end and next_sent.get('paragraph_index', 0) > sent_dict.get('paragraph_index', 0):
                    should_end = True
            
            if should_end:
                fragment_text = ''.join([s['text'] for s in current_fragment])
                # å³ä½¿ä¸æ»¡è¶³æœ€å°é•¿åº¦ï¼Œå¦‚æœè¾¾åˆ°æœ€å¤§é•¿åº¦ä¹Ÿè¦ä¿å­˜
                if len(fragment_text) >= self.min_length or current_length >= self.max_length:
                    fragments.append({
                        'text': fragment_text,
                        'index': len(fragments),
                        'length': len(fragment_text),
                        'sentence_count': len(current_fragment),
                        'paragraph_count': len(set(s.get('paragraph_index', 0) for s in current_fragment))
                    })
                current_fragment = []
                current_length = 0
        
        # å¤„ç†å‰©ä½™çš„ç‰‡æ®µ
        # å³ä½¿ä¸æ»¡è¶³æœ€å°é•¿åº¦ï¼Œä¹Ÿè¦ä¿å­˜ï¼ˆé¿å…ä¸¢å¤±å†…å®¹ï¼‰
        if current_fragment:
            fragment_text = ''.join([s['text'] for s in current_fragment])
            # å¦‚æœå‰©ä½™ç‰‡æ®µé•¿åº¦å¤§äº0ï¼Œå°±ä¿å­˜ï¼ˆå³ä½¿å°äºmin_lengthï¼‰
            # è¿™æ ·å¯ä»¥ç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½è¢«å¤„ç†
            if len(fragment_text) > 0:
                fragments.append({
                    'text': fragment_text,
                    'index': len(fragments),
                    'length': len(fragment_text),
                    'sentence_count': len(current_fragment),
                    'paragraph_count': len(set(s.get('paragraph_index', 0) for s in current_fragment))
                })
        
        return fragments
    
    def detect_chapters(self, text: str) -> List[Dict[str, any]]:
        """
        æ£€æµ‹å°è¯´ç« èŠ‚
        
        Args:
            text: å°è¯´æ–‡æœ¬
        
        Returns:
            ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªç« èŠ‚åŒ…å«æ ‡é¢˜ã€èµ·å§‹ä½ç½®ã€ç»“æŸä½ç½®ç­‰ä¿¡æ¯
        """
        chapters = []
        
        # å¸¸è§çš„ç« èŠ‚æ ‡é¢˜æ¨¡å¼
        # åŒ¹é…ï¼šç¬¬Xç« ã€ç¬¬XèŠ‚ã€Chapter Xã€ç¬¬ä¸€ç« ã€ç¬¬1ç« ç­‰
        chapter_patterns = [
            r'ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+ç« [^\n]*',  # ç¬¬Xç« 
            r'ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+èŠ‚[^\n]*',  # ç¬¬XèŠ‚
            r'Chapter\s+\d+[^\n]*',  # Chapter X
            r'CHAPTER\s+\d+[^\n]*',   # CHAPTER X
            r'ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+å›[^\n]*',  # ç¬¬Xå›
        ]
        
        # åˆå¹¶æ‰€æœ‰æ¨¡å¼
        pattern = '|'.join(f'({p})' for p in chapter_patterns)
        
        # æŸ¥æ‰¾æ‰€æœ‰ç« èŠ‚æ ‡é¢˜
        matches = list(re.finditer(pattern, text))
        
        if not matches:
            print("âš ï¸ æœªæ£€æµ‹åˆ°ç« èŠ‚æ ‡é¢˜ï¼Œå°†æ•´ä¸ªå°è¯´ä½œä¸ºä¸€ä¸ªç« èŠ‚")
            return [{
                'chapter_num': 1,
                'title': 'å…¨æ–‡',
                'start_pos': 0,
                'end_pos': len(text)
            }]
        
        # æ„å»ºç« èŠ‚åˆ—è¡¨
        for i, match in enumerate(matches):
            chapter_title = match.group().strip()
            start_pos = match.start()
            
            # ç¡®å®šç»“æŸä½ç½®ï¼ˆä¸‹ä¸€ä¸ªç« èŠ‚çš„å¼€å§‹ï¼Œæˆ–æ–‡æœ¬ç»“å°¾ï¼‰
            if i + 1 < len(matches):
                end_pos = matches[i + 1].start()
            else:
                end_pos = len(text)
            
            # æå–ç« èŠ‚å·ï¼ˆå°è¯•ä»æ ‡é¢˜ä¸­æå–æ•°å­—ï¼‰
            chapter_num = i + 1
            num_match = re.search(r'[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡]|\d+', chapter_title)
            if num_match:
                # ç®€å•å¤„ç†ï¼šå¦‚æœæ‰¾åˆ°æ•°å­—ï¼Œå°è¯•è§£æ
                try:
                    # è¿™é‡Œå¯ä»¥æ‰©å±•æ”¯æŒä¸­æ–‡æ•°å­—è½¬æ¢
                    chapter_num = i + 1  # æš‚æ—¶ä½¿ç”¨åºå·
                except:
                    chapter_num = i + 1
            
            chapters.append({
                'chapter_num': chapter_num,
                'title': chapter_title,
                'start_pos': start_pos,
                'end_pos': end_pos
            })
        
        print(f"ğŸ“‘ æ£€æµ‹åˆ° {len(chapters)} ä¸ªç« èŠ‚")
        return chapters
    
    def process(self, file_path: str, split_by_chapters: bool = False) -> Union[List[Dict[str, any]], Dict[str, any]]:
        """
        å®Œæ•´å¤„ç†æµç¨‹ï¼šåŠ è½½å°è¯´ -> æ¸…ç† -> åˆ‡åˆ†
        
        Args:
            file_path: å°è¯´æ–‡ä»¶è·¯å¾„
            split_by_chapters: æ˜¯å¦æŒ‰ç« èŠ‚åˆ‡åˆ†
        
        Returns:
            å¦‚æœ split_by_chapters=Trueï¼Œè¿”å›åŒ…å«ç« èŠ‚ä¿¡æ¯çš„å­—å…¸
            å¦åˆ™è¿”å›ç‰‡æ®µåˆ—è¡¨
        """
        # 1. åŠ è½½å°è¯´
        text = self.load_novel(file_path)
        
        # 2. æ¸…ç†æ–‡æœ¬
        text = self.clean_text(text)
        
        print(f"ğŸ“– å°è¯´æ€»é•¿åº¦: {len(text)} å­—ç¬¦")
        
        if split_by_chapters:
            # æŒ‰ç« èŠ‚å¤„ç†
            chapters = self.detect_chapters(text)
            
            chapters_data = {}
            total_fragments = 0
            
            for chapter in chapters:
                chapter_num = chapter['chapter_num']
                chapter_title = chapter['title']
                chapter_text = text[chapter['start_pos']:chapter['end_pos']]
                
                print(f"\nå¤„ç†ç« èŠ‚ {chapter_num}: {chapter_title}")
                print(f"  ç« èŠ‚é•¿åº¦: {len(chapter_text)} å­—ç¬¦")
                
                # æŒ‰å¥å­åˆ‡åˆ†
                sentences = self.split_by_sentences(chapter_text)
                
                # ç»„åˆæˆç‰‡æ®µ
                fragments = self.create_fragments(sentences)
                
                # ä¸ºæ¯ä¸ªç‰‡æ®µæ·»åŠ ç« èŠ‚ä¿¡æ¯
                for frag in fragments:
                    frag['chapter_num'] = chapter_num
                    frag['chapter_title'] = chapter_title
                
                chapters_data[chapter_num] = {
                    'chapter_num': chapter_num,
                    'title': chapter_title,
                    'fragments': fragments
                }
                
                total_fragments += len(fragments)
                print(f"  ç”Ÿæˆ {len(fragments)} ä¸ªç‰‡æ®µ")
            
            return {
                'chapters': chapters_data,
                'total_fragments': total_fragments
            }
        else:
            # ä¸æŒ‰ç« èŠ‚ï¼Œæ•´ä½“å¤„ç†
            # 3. æŒ‰å¥å­åˆ‡åˆ†ï¼ˆä¿ç•™æ ‡ç‚¹ï¼Œå¤„ç†å¼•å·ï¼Œè€ƒè™‘æ®µè½ï¼‰
            sentences = self.split_by_sentences(text)
            print(f"ğŸ“ å…±åˆ‡åˆ†å‡º {len(sentences)} ä¸ªå¥å­ï¼ˆä¿ç•™æ ‡ç‚¹ç¬¦å·ï¼‰")
            
            # 4. ç»„åˆæˆç‰‡æ®µï¼ˆä¼˜å…ˆåœ¨æ®µè½è¾¹ç•Œåˆ‡åˆ†ï¼‰
            fragments = self.create_fragments(sentences)
            print(f"ğŸ“š å…±ç”Ÿæˆ {len(fragments)} ä¸ªç‰‡æ®µ")
            
            return fragments


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    processor = NovelProcessor(min_length=50, max_length=300)
    
    # åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ–‡ä»¶ï¼ˆåŒ…å«å¯¹è¯å’Œæ®µè½ç»“æ„ï¼‰
    test_text = """"""
    
    # ä¿å­˜æµ‹è¯•æ–‡ä»¶
    test_file = Path("data/test_novel.txt")
    with open(test_file, 'r', encoding='utf-8') as f:
        test_text = f.read()

    # æµ‹è¯•å¥å­åˆ‡åˆ†
    print(test_text)
    print("=" * 60)
    print("æµ‹è¯•å¥å­åˆ‡åˆ†ï¼ˆä¿ç•™æ ‡ç‚¹ï¼Œå¤„ç†å¼•å·ï¼‰")
    print("=" * 60)
    sentences = processor.split_by_sentences(test_text)
    print(f"\nå…±åˆ‡åˆ†å‡º {len(sentences)} ä¸ªå¥å­:")
    for i, sent in enumerate(sentences[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"\nå¥å­ {i+1}:")
        print(f"  æ–‡æœ¬: {sent['text']}")
        print(f"  æ®µè½ç´¢å¼•: {sent['paragraph_index']}")
        print(f"  æ˜¯å¦æ®µè½æœ«å°¾: {sent['is_paragraph_end']}")
    
    # å¤„ç†æµ‹è¯•æ–‡ä»¶
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæ•´æµç¨‹")
    print("=" * 60)
    fragments = processor.process(str(test_file))
    
    print("\nç”Ÿæˆçš„ç‰‡æ®µ:")
    for frag in fragments[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
        print(f"\nç‰‡æ®µ {frag['index'] + 1}:")
        print(f"  é•¿åº¦: {frag['length']} å­—ç¬¦")
        print(f"  å¥å­æ•°: {frag['sentence_count']}")
        print(f"  æ®µè½æ•°: {frag.get('paragraph_count', 1)}")
        print(f"  å†…å®¹: {frag['text']}")

